import asyncio
import logging
import shutil
from pathlib import Path
from tempfile import mkdtemp
from typing import Any

import anyio
from anyio.to_thread import run_sync
from pydantic import Field, create_model

from geekcon.chat import chat_client
from geekcon.chat.leak_info import LEAK_INFO_PROMPT, LEAK_TYPE_INFO_MAP, BaseLeakedInfo
from geekcon.chat.leak_type import LEAK_TYPE_PROMPT, LeakType, LeakTypeChatResp

logger = logging.getLogger(__name__)


async def chat_for_leak_type(content: str, filename: str):
    completion = await chat_client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": LEAK_TYPE_PROMPT},
            {
                "role": "user",
                "content": f"`{filename}`:\n" + f"```\n{content}\n```",
            },
        ],
        response_format=LeakTypeChatResp,
        timeout=10,
    )
    result = completion.choices[0].message.parsed
    assert result
    logger.info("Leak type for file %r: %r", filename, result)
    return result.leak_types


async def chat_for_leak_content(
    leak_types: list[LeakType], filename: str, content: str
):
    field_definitions: dict[str, tuple[type, Any]] = {
        leak_type.name.lower(): (
            LEAK_TYPE_INFO_MAP[leak_type],
            Field(..., description=leak_type.value),
        )
        for leak_type in leak_types
    }
    response_format = create_model(
        "DynamicLeakInfo", field_definitions=field_definitions
    )
    completion = await chat_client.beta.chat.completions.parse(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": LEAK_INFO_PROMPT},
            {
                "role": "user",
                "content": f"`{filename}`:\n" + f"```\n{content}\n```",
            },
        ],
        timeout=60,
        response_format=response_format,
    )
    result = completion.choices[0].message.parsed
    assert result
    logger.info("Leaked info for file %r: %r", filename, result)
    data: dict[str, BaseLeakedInfo] = result.model_dump()
    return {LeakType[k.upper()].value: v.to_response() for k, v in data.items()}


class PentestChallenge:
    def __init__(self, zip_file: str):
        self.zip_file = zip_file
        current_loop = asyncio.get_running_loop()
        self.result_future: asyncio.Future[dict[str, dict[str, Any]]] = (
            current_loop.create_future()
        )

    async def solve(self):
        extracted_dir = Path(mkdtemp())
        await run_sync(shutil.unpack_archive, self.zip_file, extracted_dir)
        all_files = [file for file in extracted_dir.glob("**/*") if file.is_file()]

        async def read_file(file: Path):
            async with await anyio.open_file(
                file, "r", encoding="utf-8", errors="ignore"
            ) as f:
                return await f.read()

        all_file_contents = await asyncio.gather(
            *(read_file(file) for file in all_files)
        )

        async def solve_single_challenge(file: Path, content: str):
            leak_types = await chat_for_leak_type(content, file.name)
            return await chat_for_leak_content(leak_types, file.name, content)

        results = await asyncio.gather(
            *(
                solve_single_challenge(file, content)
                for file, content in zip(all_files, all_file_contents, strict=True)
            ),
            return_exceptions=True,
        )

        return_results: dict[str, dict[str, Any]] = {}
        for file, result in zip(all_files, results, strict=True):
            match result:
                case dict(data):
                    return_results[file.name] = data
                case Exception() as exc:
                    logger.error(
                        "Failed to resolve challenge for file %r", file, exc_info=exc
                    )
                case BaseException() as exc:
                    raise exc
        self.result_future.set_result(return_results)
